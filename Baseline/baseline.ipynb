{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd64341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import string\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3e9c7",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44e7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"Initialize the attributes of the object of the class.\"\"\"\n",
    "        \n",
    "        # data directory\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        # load text dataset  \n",
    "        self.sentences = self._read_data(data_dir, 'sentences')\n",
    "\n",
    "        # load text dataset  \n",
    "        self.labels = self._read_data(data_dir, 'labels')  \n",
    "        \n",
    "    \n",
    "       \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the size of the dataset.\"\"\"\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data sample for a given index, along with the lable of the corresponding tweet\"\"\"\n",
    "        \n",
    "        \n",
    "        # - get the data sample corresponding to 'index' (use the list 'self.image_path_list')\n",
    "        data_sample = self.sentences[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        features = {'sents': data_sample, 'labels': label}\n",
    "        \n",
    "        \n",
    "        return features\n",
    "\n",
    " \n",
    "    \n",
    "    def _label_map(self,label,class_num=3):\n",
    "        \n",
    "        \"\"\" convert to labels to one hot vectors\"\"\"\n",
    "        \n",
    "        one_hot = torch.zeros(class_num, dtype=torch.int32)\n",
    "        idx = self.label_to_index[label.upper()]\n",
    "        if idx!=-1:\n",
    "            one_hot[idx] = 1\n",
    "        \n",
    "        return one_hot\n",
    "            \n",
    "            \n",
    "    \n",
    "    def _read_data(self, path, pattern):\n",
    "        \n",
    "        \"\"\" read txt file and return as list of strings\"\"\"\n",
    "        \n",
    "        path = f'{path}/{pattern}.txt'\n",
    "        with open(path, 'r') as file:\n",
    "            data = [line.strip() for line in file]\n",
    "\n",
    "        \n",
    "        return data\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd764f",
   "metadata": {},
   "source": [
    "### Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86900685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = EntityDataset('../Dataset/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e71d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee8510d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Recent', 'work', 'in', 'natural', 'language', 'generation', 'has', 'begun', 'to', 'take', 'linguistic', 'variation', 'into', 'account', 'developing', 'algorithms', 'that', 'are', 'capable', 'of', 'modifying', 'the', 'system', \"'s\", 'linguistic', 'style', 'based', 'either', 'on', 'the', 'user', \"'s\", 'linguistic', 'style', 'or', 'other', 'factors', 'such', 'as', 'personality', 'or', 'politeness']\n",
      "['O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# print an example batch\n",
    "\n",
    "batch_example = next(iter(test_dataloader))\n",
    "tweet_batch_example = batch_example['sents']\n",
    "labels_batch_example = batch_example['labels']\n",
    "\n",
    "print(tweet_batch_example[0].split())\n",
    "print(labels_batch_example[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e7b75d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = []\n",
    "preds = []\n",
    "for batch in iter(test_dataloader):\n",
    "    for labels in batch['labels']:\n",
    "        labels = labels.replace('0','O')\n",
    "        true.extend(labels.upper().split())\n",
    "        preds.extend(['O' for i in range(len(labels.split()))])\n",
    "        \n",
    "        \n",
    "len(true)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4f021b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00       328\n",
      "           I       0.00      0.00      0.00       339\n",
      "           O       0.73      1.00      0.84      1801\n",
      "\n",
      "    accuracy                           0.73      2468\n",
      "   macro avg       0.24      0.33      0.28      2468\n",
      "weighted avg       0.53      0.73      0.62      2468\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hossain/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hossain/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hossain/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe70aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
